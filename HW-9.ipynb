{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание №9. Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import torchmetrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import transformers\n",
    "from transformers import pipeline\n",
    "from transformers import BertTokenizer, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание\n",
    "\n",
    "1. Возьмите готовую модель из https://huggingface.co/models для классификации сентимента текста.\n",
    "\n",
    "2. Сделайте предсказания на всем df_val. Посчитайте метрику качества.\n",
    "\n",
    "3. Дообучите эту модель на df_train. Посчитайте метрику качества на df_val."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## План работы\n",
    "\n",
    "[0. Модель классификации сентимента текста 'SkolkovoInstitute/russian_toxicity_classifier'](#section_0)\n",
    "\n",
    "[1. Загрузка данных](#section_1)\n",
    "\n",
    "[2. Dataset и Dataloader](#section_2)\n",
    "    \n",
    "[3. Метрика модели 'SkolkovoInstitute/russian_toxicity_classifier' на валидационном датасете](#section_3)\n",
    "\n",
    "[4. Дообученная модель 'SkolkovoInstitute/russian_toxicity_classifier' и ее метрики](#section_4)\n",
    "\n",
    "[5. Выводы](#section_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Модель классификации сентимента текста 'SkolkovoInstitute/russian_toxicity_classifier'  <a id='section_0'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Описание классификатора SkolkovoInstitute/russian_toxicity_classifier**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bert-based classifier (finetuned from [Conversational Rubert](https://huggingface.co/DeepPavlov/rubert-base-cased-conversational)) trained on merge of Russian Language Toxic Comments [dataset](https://www.kaggle.com/blackmoon/russian-language-toxic-comments/metadata) collected from 2ch.hk and Toxic Russian Comments [dataset](https://www.kaggle.com/alexandersemiletov/toxic-russian-comments) collected from ok.ru.\n",
    "\n",
    "The datasets were merged, shuffled, and split into train, dev, test splits in 80-10-10 proportion.\n",
    "The metrics obtained from test dataset is as follows\n",
    "\n",
    "|              | precision | recall | f1-score | support |\n",
    "|:------------:|:---------:|:------:|:--------:|:-------:|\n",
    "|       0      |    0.98   |  0.99  |   0.98   | 21384   |\n",
    "|       1      |    0.94   |  0.92  |   0.93   | 4886    |\n",
    "|   accuracy   |       |   |   0.97  |         26270|\n",
    "| macro avg    | 0.96      | 0.96   | 0.96     | 26270   |\n",
    "| weighted avg | 0.97      | 0.97   | 0.97     | 26270   |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertForSequenceClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
      ")\n",
      "Parameters full train: 177854978\n"
     ]
    }
   ],
   "source": [
    "# загрузка модели\n",
    "model_bert = BertForSequenceClassification.from_pretrained('SkolkovoInstitute/russian_toxicity_classifier')\n",
    "print(model_bert)\n",
    "print(\"Parameters full train:\", sum([param.nelement() for param in model_bert.parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'neutral', 'score': 0.998418927192688}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#пример классификации сентимента текста\n",
    "sentiment = pipeline(\"text-classification\", model='SkolkovoInstitute/russian_toxicity_classifier')\n",
    "sentiment(\"Этот ресторан отличный\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101, 17863, 10316,   949, 15427,   831,  2703,   102,     0,     0]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "#пример работы токенизации\n",
    "tokenizer = BertTokenizer.from_pretrained('SkolkovoInstitute/russian_toxicity_classifier')\n",
    "\n",
    "example_text = 'Пример текста для токенизации'\n",
    "\n",
    "bert_input = tokenizer(example_text, padding='max_length', max_length=10, \n",
    "                       truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "\n",
    "print(bert_input['input_ids'])\n",
    "print(bert_input['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('[CLS]', 'Пример', 'текста')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.ids_to_tokens[101], tokenizer.ids_to_tokens[17863], tokenizer.ids_to_tokens[10316]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'[PAD]': 0,\n",
       " '[unused1]': 1,\n",
       " '[unused2]': 2,\n",
       " '[unused3]': 3,\n",
       " '[unused4]': 4,\n",
       " '[unused5]': 5,\n",
       " '[unused6]': 6,\n",
       " '[unused7]': 7,\n",
       " '[unused8]': 8,\n",
       " '[unused9]': 9,\n",
       " '[unused10]': 10,\n",
       " '[unused11]': 11,\n",
       " '[unused12]': 12,\n",
       " '[unused13]': 13,\n",
       " '[unused14]': 14,\n",
       " '[unused15]': 15,\n",
       " '[unused16]': 16,\n",
       " '[unused17]': 17,\n",
       " '[unused18]': 18,\n",
       " '[unused19]': 19,\n",
       " '[unused20]': 20,\n",
       " '[unused21]': 21,\n",
       " '[unused22]': 22,\n",
       " '[unused23]': 23,\n",
       " '[unused24]': 24,\n",
       " '[unused25]': 25,\n",
       " '[unused26]': 26,\n",
       " '[unused27]': 27,\n",
       " '[unused28]': 28,\n",
       " '[unused29]': 29,\n",
       " '[unused30]': 30,\n",
       " '[unused31]': 31,\n",
       " '[unused32]': 32,\n",
       " '[unused33]': 33,\n",
       " '[unused34]': 34,\n",
       " '[unused35]': 35,\n",
       " '[unused36]': 36,\n",
       " '[unused37]': 37,\n",
       " '[unused38]': 38,\n",
       " '[unused39]': 39,\n",
       " '[unused40]': 40,\n",
       " '[unused41]': 41,\n",
       " '[unused42]': 42,\n",
       " '[unused43]': 43,\n",
       " '[unused44]': 44,\n",
       " '[unused45]': 45,\n",
       " '[unused46]': 46,\n",
       " '[unused47]': 47,\n",
       " '[unused48]': 48,\n",
       " '[unused49]': 49,\n",
       " '[unused50]': 50,\n",
       " '[unused51]': 51,\n",
       " '[unused52]': 52,\n",
       " '[unused53]': 53,\n",
       " '[unused54]': 54,\n",
       " '[unused55]': 55,\n",
       " '[unused56]': 56,\n",
       " '[unused57]': 57,\n",
       " '[unused58]': 58,\n",
       " '[unused59]': 59,\n",
       " '[unused60]': 60,\n",
       " '[unused61]': 61,\n",
       " '[unused62]': 62,\n",
       " '[unused63]': 63,\n",
       " '[unused64]': 64,\n",
       " '[unused65]': 65,\n",
       " '[unused66]': 66,\n",
       " '[unused67]': 67,\n",
       " '[unused68]': 68,\n",
       " '[unused69]': 69,\n",
       " '[unused70]': 70,\n",
       " '[unused71]': 71,\n",
       " '[unused72]': 72,\n",
       " '[unused73]': 73,\n",
       " '[unused74]': 74,\n",
       " '[unused75]': 75,\n",
       " '[unused76]': 76,\n",
       " '[unused77]': 77,\n",
       " '[unused78]': 78,\n",
       " '[unused79]': 79,\n",
       " '[unused80]': 80,\n",
       " '[unused81]': 81,\n",
       " '[unused82]': 82,\n",
       " '[unused83]': 83,\n",
       " '[unused84]': 84,\n",
       " '[unused85]': 85,\n",
       " '[unused86]': 86,\n",
       " '[unused87]': 87,\n",
       " '[unused88]': 88,\n",
       " '[unused89]': 89,\n",
       " '[unused90]': 90,\n",
       " '[unused91]': 91,\n",
       " '[unused92]': 92,\n",
       " '[unused93]': 93,\n",
       " '[unused94]': 94,\n",
       " '[unused95]': 95,\n",
       " '[unused96]': 96,\n",
       " '[unused97]': 97,\n",
       " '[unused98]': 98,\n",
       " '[unused99]': 99,\n",
       " '[UNK]': 100,\n",
       " '[CLS]': 101,\n",
       " '[SEP]': 102,\n",
       " '[MASK]': 103,\n",
       " '<S>': 104,\n",
       " '<T>': 105,\n",
       " '!': 106,\n",
       " '##!': 107,\n",
       " '\"': 108,\n",
       " '##\"': 109,\n",
       " '#': 110,\n",
       " '###': 111,\n",
       " '$': 112,\n",
       " '##$': 113,\n",
       " '%': 114,\n",
       " '##%': 115,\n",
       " '&': 116,\n",
       " '##&': 117,\n",
       " \"'\": 118,\n",
       " \"##'\": 119,\n",
       " '(': 120,\n",
       " '##(': 121,\n",
       " ')': 122,\n",
       " '##)': 123,\n",
       " '*': 124,\n",
       " '##*': 125,\n",
       " '+': 126,\n",
       " '##+': 127,\n",
       " ',': 128,\n",
       " '##,': 129,\n",
       " '-': 130,\n",
       " '##-': 131,\n",
       " '.': 132,\n",
       " '##.': 133,\n",
       " '/': 134,\n",
       " '##/': 135,\n",
       " '0': 136,\n",
       " '##0': 137,\n",
       " '1': 138,\n",
       " '##1': 139,\n",
       " '2': 140,\n",
       " '##2': 141,\n",
       " '3': 142,\n",
       " '##3': 143,\n",
       " '4': 144,\n",
       " '##4': 145,\n",
       " '5': 146,\n",
       " '##5': 147,\n",
       " '6': 148,\n",
       " '##6': 149,\n",
       " '7': 150,\n",
       " '##7': 151,\n",
       " '8': 152,\n",
       " '##8': 153,\n",
       " '9': 154,\n",
       " '##9': 155,\n",
       " ':': 156,\n",
       " '##:': 157,\n",
       " ';': 158,\n",
       " '##;': 159,\n",
       " '<': 160,\n",
       " '##<': 161,\n",
       " '=': 162,\n",
       " '##=': 163,\n",
       " '>': 164,\n",
       " '##>': 165,\n",
       " '?': 166,\n",
       " '##?': 167,\n",
       " '@': 168,\n",
       " '##@': 169,\n",
       " 'A': 170,\n",
       " '##A': 171,\n",
       " 'B': 172,\n",
       " '##B': 173,\n",
       " 'C': 174,\n",
       " '##C': 175,\n",
       " 'D': 176,\n",
       " '##D': 177,\n",
       " 'E': 178,\n",
       " '##E': 179,\n",
       " 'F': 180,\n",
       " '##F': 181,\n",
       " 'G': 182,\n",
       " '##G': 183,\n",
       " 'H': 184,\n",
       " '##H': 185,\n",
       " 'I': 186,\n",
       " '##I': 187,\n",
       " 'J': 188,\n",
       " '##J': 189,\n",
       " 'K': 190,\n",
       " '##K': 191,\n",
       " 'L': 192,\n",
       " '##L': 193,\n",
       " 'M': 194,\n",
       " '##M': 195,\n",
       " 'N': 196,\n",
       " '##N': 197,\n",
       " 'O': 198,\n",
       " '##O': 199,\n",
       " 'P': 200,\n",
       " '##P': 201,\n",
       " 'Q': 202,\n",
       " '##Q': 203,\n",
       " 'R': 204,\n",
       " '##R': 205,\n",
       " 'S': 206,\n",
       " '##S': 207,\n",
       " 'T': 208,\n",
       " '##T': 209,\n",
       " 'U': 210,\n",
       " '##U': 211,\n",
       " 'V': 212,\n",
       " '##V': 213,\n",
       " 'W': 214,\n",
       " '##W': 215,\n",
       " 'X': 216,\n",
       " '##X': 217,\n",
       " 'Y': 218,\n",
       " '##Y': 219,\n",
       " 'Z': 220,\n",
       " '##Z': 221,\n",
       " '[': 222,\n",
       " '##[': 223,\n",
       " '\\\\': 224,\n",
       " '##\\\\': 225,\n",
       " ']': 226,\n",
       " '##]': 227,\n",
       " '^': 228,\n",
       " '##^': 229,\n",
       " '_': 230,\n",
       " '##_': 231,\n",
       " 'a': 232,\n",
       " '##a': 233,\n",
       " 'b': 234,\n",
       " '##b': 235,\n",
       " 'c': 236,\n",
       " '##c': 237,\n",
       " 'd': 238,\n",
       " '##d': 239,\n",
       " 'e': 240,\n",
       " '##e': 241,\n",
       " 'f': 242,\n",
       " '##f': 243,\n",
       " 'g': 244,\n",
       " '##g': 245,\n",
       " 'h': 246,\n",
       " '##h': 247,\n",
       " 'i': 248,\n",
       " '##i': 249,\n",
       " 'j': 250,\n",
       " '##j': 251,\n",
       " 'k': 252,\n",
       " '##k': 253,\n",
       " 'l': 254,\n",
       " '##l': 255,\n",
       " 'm': 256,\n",
       " '##m': 257,\n",
       " 'n': 258,\n",
       " '##n': 259,\n",
       " 'o': 260,\n",
       " '##o': 261,\n",
       " 'p': 262,\n",
       " '##p': 263,\n",
       " 'q': 264,\n",
       " '##q': 265,\n",
       " 'r': 266,\n",
       " '##r': 267,\n",
       " 's': 268,\n",
       " '##s': 269,\n",
       " 't': 270,\n",
       " '##t': 271,\n",
       " 'u': 272,\n",
       " '##u': 273,\n",
       " 'v': 274,\n",
       " '##v': 275,\n",
       " 'w': 276,\n",
       " '##w': 277,\n",
       " 'x': 278,\n",
       " '##x': 279,\n",
       " 'y': 280,\n",
       " '##y': 281,\n",
       " 'z': 282,\n",
       " '##z': 283,\n",
       " '{': 284,\n",
       " '##{': 285,\n",
       " '|': 286,\n",
       " '##|': 287,\n",
       " '}': 288,\n",
       " '##}': 289,\n",
       " '~': 290,\n",
       " '##~': 291,\n",
       " 'о': 292,\n",
       " '##о': 293,\n",
       " 'е': 294,\n",
       " '£': 295,\n",
       " '##£': 296,\n",
       " '##е': 297,\n",
       " '¦': 298,\n",
       " '§': 299,\n",
       " '##§': 300,\n",
       " 'а': 301,\n",
       " '©': 302,\n",
       " '##а': 303,\n",
       " '«': 304,\n",
       " '##«': 305,\n",
       " '¬': 306,\n",
       " '##¬': 307,\n",
       " '®': 308,\n",
       " '##®': 309,\n",
       " '°': 310,\n",
       " '##°': 311,\n",
       " '±': 312,\n",
       " '##±': 313,\n",
       " '²': 314,\n",
       " '##²': 315,\n",
       " '³': 316,\n",
       " '##³': 317,\n",
       " 'µ': 318,\n",
       " '¶': 319,\n",
       " '·': 320,\n",
       " '##·': 321,\n",
       " 'и': 322,\n",
       " '##и': 323,\n",
       " 'º': 324,\n",
       " '##º': 325,\n",
       " '»': 326,\n",
       " '##»': 327,\n",
       " '¼': 328,\n",
       " '##¼': 329,\n",
       " '½': 330,\n",
       " '##½': 331,\n",
       " 'т': 332,\n",
       " '##т': 333,\n",
       " 'н': 334,\n",
       " '##н': 335,\n",
       " 'с': 336,\n",
       " '##с': 337,\n",
       " 'р': 338,\n",
       " '##р': 339,\n",
       " 'в': 340,\n",
       " '##в': 341,\n",
       " 'л': 342,\n",
       " '##л': 343,\n",
       " 'к': 344,\n",
       " '##к': 345,\n",
       " 'м': 346,\n",
       " '##м': 347,\n",
       " 'д': 348,\n",
       " '##д': 349,\n",
       " 'п': 350,\n",
       " '##п': 351,\n",
       " 'у': 352,\n",
       " '##у': 353,\n",
       " 'ы': 354,\n",
       " '##ы': 355,\n",
       " 'ь': 356,\n",
       " '##ь': 357,\n",
       " 'я': 358,\n",
       " '##я': 359,\n",
       " 'б': 360,\n",
       " '##б': 361,\n",
       " 'ч': 362,\n",
       " '×': 363,\n",
       " '##×': 364,\n",
       " '##ч': 365,\n",
       " 'з': 366,\n",
       " '##з': 367,\n",
       " 'г': 368,\n",
       " '##г': 369,\n",
       " 'й': 370,\n",
       " '##й': 371,\n",
       " 'ж': 372,\n",
       " 'ß': 373,\n",
       " '##ß': 374,\n",
       " 'à': 375,\n",
       " '##à': 376,\n",
       " 'á': 377,\n",
       " '##á': 378,\n",
       " '##ж': 379,\n",
       " 'х': 380,\n",
       " '##х': 381,\n",
       " 'ш': 382,\n",
       " 'ä': 383,\n",
       " '##ä': 384,\n",
       " 'å': 385,\n",
       " '##å': 386,\n",
       " 'æ': 387,\n",
       " '##æ': 388,\n",
       " 'ç': 389,\n",
       " '##ç': 390,\n",
       " 'è': 391,\n",
       " '##è': 392,\n",
       " 'é': 393,\n",
       " '##é': 394,\n",
       " 'ê': 395,\n",
       " '##ê': 396,\n",
       " 'ë': 397,\n",
       " '##ë': 398,\n",
       " 'ì': 399,\n",
       " '##ì': 400,\n",
       " 'í': 401,\n",
       " '##í': 402,\n",
       " '##ш': 403,\n",
       " 'ю': 404,\n",
       " '##ю': 405,\n",
       " 'ц': 406,\n",
       " 'ð': 407,\n",
       " '##ð': 408,\n",
       " 'ñ': 409,\n",
       " '##ñ': 410,\n",
       " '##ц': 411,\n",
       " 'э': 412,\n",
       " 'ó': 413,\n",
       " '##ó': 414,\n",
       " 'ô': 415,\n",
       " '##ô': 416,\n",
       " '##э': 417,\n",
       " 'щ': 418,\n",
       " 'ö': 419,\n",
       " '##ö': 420,\n",
       " '÷': 421,\n",
       " '##÷': 422,\n",
       " 'ø': 423,\n",
       " '##ø': 424,\n",
       " '##щ': 425,\n",
       " 'ф': 426,\n",
       " 'ú': 427,\n",
       " '##ú': 428,\n",
       " '##ф': 429,\n",
       " 'П': 430,\n",
       " 'ü': 431,\n",
       " '##ü': 432,\n",
       " 'ý': 433,\n",
       " '##ý': 434,\n",
       " '##П': 435,\n",
       " 'В': 436,\n",
       " '##В': 437,\n",
       " 'Н': 438,\n",
       " '##Н': 439,\n",
       " 'ā': 440,\n",
       " '##ā': 441,\n",
       " 'С': 442,\n",
       " '##С': 443,\n",
       " '—': 444,\n",
       " 'А': 445,\n",
       " 'ą': 446,\n",
       " '##ą': 447,\n",
       " '##А': 448,\n",
       " 'ć': 449,\n",
       " '##ć': 450,\n",
       " 'К': 451,\n",
       " '##К': 452,\n",
       " 'č': 453,\n",
       " '##č': 454,\n",
       " '–': 455,\n",
       " 'О': 456,\n",
       " '##О': 457,\n",
       " 'И': 458,\n",
       " '##И': 459,\n",
       " 'ē': 460,\n",
       " '##ē': 461,\n",
       " 'ё': 462,\n",
       " '##ё': 463,\n",
       " 'Т': 464,\n",
       " '##Т': 465,\n",
       " 'Д': 466,\n",
       " '##Д': 467,\n",
       " 'ę': 468,\n",
       " '##ę': 469,\n",
       " 'ě': 470,\n",
       " '##ě': 471,\n",
       " 'М': 472,\n",
       " '##М': 473,\n",
       " 'Р': 474,\n",
       " '##Р': 475,\n",
       " 'Е': 476,\n",
       " '##Е': 477,\n",
       " 'Я': 478,\n",
       " '##Я': 479,\n",
       " 'Б': 480,\n",
       " '##Б': 481,\n",
       " 'ī': 482,\n",
       " '##ī': 483,\n",
       " 'Э': 484,\n",
       " '##Э': 485,\n",
       " 'У': 486,\n",
       " '##У': 487,\n",
       " 'ı': 488,\n",
       " '##ı': 489,\n",
       " 'Г': 490,\n",
       " '##Г': 491,\n",
       " 'З': 492,\n",
       " '##З': 493,\n",
       " 'Л': 494,\n",
       " '##Л': 495,\n",
       " 'Ч': 496,\n",
       " '##Ч': 497,\n",
       " 'Х': 498,\n",
       " 'ł': 499,\n",
       " '##ł': 500,\n",
       " '##Х': 501,\n",
       " 'Ф': 502,\n",
       " '##Ф': 503,\n",
       " 'ъ': 504,\n",
       " '##ъ': 505,\n",
       " 'Ш': 506,\n",
       " '##Ш': 507,\n",
       " 'Ж': 508,\n",
       " '##Ж': 509,\n",
       " 'Ц': 510,\n",
       " '##Ц': 511,\n",
       " 'ō': 512,\n",
       " '##ō': 513,\n",
       " 'Ю': 514,\n",
       " '##Ю': 515,\n",
       " 'і': 516,\n",
       " '##і': 517,\n",
       " '…': 518,\n",
       " 'Ы': 519,\n",
       " '##Ы': 520,\n",
       " 'Й': 521,\n",
       " '##Й': 522,\n",
       " 'ř': 523,\n",
       " '##ř': 524,\n",
       " 'Ь': 525,\n",
       " '##Ь': 526,\n",
       " 'ś': 527,\n",
       " '##ś': 528,\n",
       " '“': 529,\n",
       " '”': 530,\n",
       " '№': 531,\n",
       " '##№': 532,\n",
       " 'Š': 533,\n",
       " '##Š': 534,\n",
       " 'š': 535,\n",
       " '##š': 536,\n",
       " 'Щ': 537,\n",
       " '##Щ': 538,\n",
       " '•': 539,\n",
       " '##•': 540,\n",
       " 'ї': 541,\n",
       " '##ї': 542,\n",
       " 'Ё': 543,\n",
       " '##Ё': 544,\n",
       " 'є': 545,\n",
       " '##є': 546,\n",
       " '’': 547,\n",
       " '↑': 548,\n",
       " '™': 549,\n",
       " '##™': 550,\n",
       " '́': 551,\n",
       " '##́': 552,\n",
       " '„': 553,\n",
       " '##„': 554,\n",
       " '−': 555,\n",
       " '##−': 556,\n",
       " 'Ъ': 557,\n",
       " '##Ъ': 558,\n",
       " 'І': 559,\n",
       " 'ż': 560,\n",
       " '##ż': 561,\n",
       " '##І': 562,\n",
       " '€': 563,\n",
       " 'ž': 564,\n",
       " '##ž': 565,\n",
       " '##€': 566,\n",
       " 'ѕ': 567,\n",
       " '`': 568,\n",
       " '‚': 569,\n",
       " '##‚': 570,\n",
       " '→': 571,\n",
       " '##→': 572,\n",
       " 'ǐ': 573,\n",
       " '♪': 574,\n",
       " 'ў': 575,\n",
       " '##ў': 576,\n",
       " 'Ѕ': 577,\n",
       " '●': 578,\n",
       " 'ѣ': 579,\n",
       " '##ѣ': 580,\n",
       " 'Ѓ': 581,\n",
       " '‘': 582,\n",
       " '―': 583,\n",
       " 'α': 584,\n",
       " '##α': 585,\n",
       " 'Ђ': 586,\n",
       " 'ə': 587,\n",
       " '##ə': 588,\n",
       " 'ɛ': 589,\n",
       " '##ɛ': 590,\n",
       " '☆': 591,\n",
       " 'ј': 592,\n",
       " '##ј': 593,\n",
       " '‑': 594,\n",
       " 'ɪ': 595,\n",
       " '##ɪ': 596,\n",
       " 'Є': 597,\n",
       " '##Є': 598,\n",
       " 'づ': 599,\n",
       " 'ґ': 600,\n",
       " 'ρ': 601,\n",
       " '##ρ': 602,\n",
       " 'ѓ': 603,\n",
       " 'λ': 604,\n",
       " '##λ': 605,\n",
       " 'Њ': 606,\n",
       " 'ε': 607,\n",
       " '##ε': 608,\n",
       " '‹': 609,\n",
       " 'ο': 610,\n",
       " '##ο': 611,\n",
       " 'ا': 612,\n",
       " '##ا': 613,\n",
       " 'Џ': 614,\n",
       " '←': 615,\n",
       " '##←': 616,\n",
       " 'π': 617,\n",
       " '##π': 618,\n",
       " 'ς': 619,\n",
       " '##ς': 620,\n",
       " 'ˈ': 621,\n",
       " '##ˈ': 622,\n",
       " 'ː': 623,\n",
       " '##ː': 624,\n",
       " '★': 625,\n",
       " 'μ': 626,\n",
       " '##μ': 627,\n",
       " '≈': 628,\n",
       " '##≈': 629,\n",
       " '‡': 630,\n",
       " '█': 631,\n",
       " 'τ': 632,\n",
       " '##τ': 633,\n",
       " 'י': 634,\n",
       " '##י': 635,\n",
       " '‿': 636,\n",
       " '̲': 637,\n",
       " '►': 638,\n",
       " 'ו': 639,\n",
       " '##ו': 640,\n",
       " 'ل': 641,\n",
       " '##ل': 642,\n",
       " 'ν': 643,\n",
       " '##ν': 644,\n",
       " 'Δ': 645,\n",
       " '##Δ': 646,\n",
       " 'َ': 647,\n",
       " '##َ': 648,\n",
       " 'ι': 649,\n",
       " '##ι': 650,\n",
       " '，': 651,\n",
       " '##，': 652,\n",
       " 'ү': 653,\n",
       " '##ү': 654,\n",
       " '″': 655,\n",
       " '##″': 656,\n",
       " 'م': 657,\n",
       " '##م': 658,\n",
       " 'δ': 659,\n",
       " '##δ': 660,\n",
       " 'γ': 661,\n",
       " '##γ': 662,\n",
       " 'ה': 663,\n",
       " '##ה': 664,\n",
       " '的': 665,\n",
       " '？': 666,\n",
       " '。': 667,\n",
       " 'Λ': 668,\n",
       " '##Λ': 669,\n",
       " '─': 670,\n",
       " '##─': 671,\n",
       " 'β': 672,\n",
       " '##β': 673,\n",
       " 'ל': 674,\n",
       " '##ל': 675,\n",
       " 'σ': 676,\n",
       " '##σ': 677,\n",
       " 'ר': 678,\n",
       " '##ר': 679,\n",
       " 'ә': 680,\n",
       " '##ә': 681,\n",
       " 'κ': 682,\n",
       " '##κ': 683,\n",
       " '≠': 684,\n",
       " 'Ї': 685,\n",
       " 'ω': 686,\n",
       " '##ω': 687,\n",
       " 'ُ': 688,\n",
       " '##ُ': 689,\n",
       " 'ת': 690,\n",
       " '##ת': 691,\n",
       " 'א': 692,\n",
       " 'ά': 693,\n",
       " '##ά': 694,\n",
       " 'έ': 695,\n",
       " '##έ': 696,\n",
       " '##א': 697,\n",
       " 'و': 698,\n",
       " 'ί': 699,\n",
       " '##ί': 700,\n",
       " '##و': 701,\n",
       " 'ن': 702,\n",
       " '##ن': 703,\n",
       " 'ツ': 704,\n",
       " 'ر': 705,\n",
       " '##ر': 706,\n",
       " 'ב': 707,\n",
       " '##ב': 708,\n",
       " 'φ': 709,\n",
       " '##φ': 710,\n",
       " 'ي': 711,\n",
       " '##ي': 712,\n",
       " 'η': 713,\n",
       " '##η': 714,\n",
       " 'θ': 715,\n",
       " '##θ': 716,\n",
       " 'מ': 717,\n",
       " '##מ': 718,\n",
       " '↓': 719,\n",
       " 'ө': 720,\n",
       " '##ө': 721,\n",
       " '′': 722,\n",
       " '##′': 723,\n",
       " 'ْ': 724,\n",
       " '##ْ': 725,\n",
       " 'қ': 726,\n",
       " '##қ': 727,\n",
       " '♦': 728,\n",
       " 'ِ': 729,\n",
       " '##ِ': 730,\n",
       " '！': 731,\n",
       " 'ό': 732,\n",
       " '##ό': 733,\n",
       " 'ש': 734,\n",
       " '##ש': 735,\n",
       " 'Ћ': 736,\n",
       " 'ب': 737,\n",
       " '##ب': 738,\n",
       " '■': 739,\n",
       " '我': 740,\n",
       " 'υ': 741,\n",
       " '##υ': 742,\n",
       " '♥': 743,\n",
       " '≤': 744,\n",
       " '##≤': 745,\n",
       " 'ְ': 746,\n",
       " '##ְ': 747,\n",
       " '学': 748,\n",
       " 'Ќ': 749,\n",
       " 'ஜ': 750,\n",
       " 'ه': 751,\n",
       " '##ه': 752,\n",
       " 'נ': 753,\n",
       " '##נ': 754,\n",
       " 'ד': 755,\n",
       " '##ד': 756,\n",
       " 'ָ': 757,\n",
       " '##ָ': 758,\n",
       " '†': 759,\n",
       " '##†': 760,\n",
       " '）': 761,\n",
       " '##）': 762,\n",
       " '数': 763,\n",
       " '≡': 764,\n",
       " '一': 765,\n",
       " '（': 766,\n",
       " '##（': 767,\n",
       " '▪': 768,\n",
       " '√': 769,\n",
       " '出': 770,\n",
       " 'ಠ': 771,\n",
       " '∞': 772,\n",
       " '你': 773,\n",
       " 'ע': 774,\n",
       " 'Ў': 775,\n",
       " '##ע': 776,\n",
       " '社': 777,\n",
       " 'د': 778,\n",
       " '##د': 779,\n",
       " '十': 780,\n",
       " '版': 781,\n",
       " '人': 782,\n",
       " '##人': 783,\n",
       " 'ם': 784,\n",
       " '##ם': 785,\n",
       " 'ғ': 786,\n",
       " '##ғ': 787,\n",
       " 'س': 788,\n",
       " '##س': 789,\n",
       " 'ң': 790,\n",
       " '##ң': 791,\n",
       " '##то': 792,\n",
       " '##но': 793,\n",
       " '##ст': 794,\n",
       " '##ро': 795,\n",
       " '##ен': 796,\n",
       " 'по': 797,\n",
       " '##ет': 798,\n",
       " '##ра': 799,\n",
       " '##ли': 800,\n",
       " 'на': 801,\n",
       " 'не': 802,\n",
       " '##ко': 803,\n",
       " '##ер': 804,\n",
       " '##ть': 805,\n",
       " '##ль': 806,\n",
       " '##ва': 807,\n",
       " '##ни': 808,\n",
       " '##го': 809,\n",
       " '##ло': 810,\n",
       " '##ри': 811,\n",
       " '##ла': 812,\n",
       " '##ка': 813,\n",
       " '##на': 814,\n",
       " '##ны': 815,\n",
       " '##во': 816,\n",
       " '##ем': 817,\n",
       " '##ки': 818,\n",
       " '##да': 819,\n",
       " '##ся': 820,\n",
       " '##та': 821,\n",
       " 'то': 822,\n",
       " 'за': 823,\n",
       " 'ко': 824,\n",
       " 'что': 825,\n",
       " '##ти': 826,\n",
       " '##ак': 827,\n",
       " '##ре': 828,\n",
       " '##те': 829,\n",
       " 'про': 830,\n",
       " '##ени': 831,\n",
       " '##ле': 832,\n",
       " '##ди': 833,\n",
       " 'ра': 834,\n",
       " '##ви': 835,\n",
       " '##де': 836,\n",
       " '##ми': 837,\n",
       " 'это': 838,\n",
       " '##не': 839,\n",
       " 'бы': 840,\n",
       " 'мо': 841,\n",
       " '##ля': 842,\n",
       " '##ру': 843,\n",
       " '##мо': 844,\n",
       " '##ма': 845,\n",
       " 'во': 846,\n",
       " 'от': 847,\n",
       " '##бо': 848,\n",
       " 'до': 849,\n",
       " 'со': 850,\n",
       " '##ес': 851,\n",
       " 'вы': 852,\n",
       " '##до': 853,\n",
       " '##чи': 854,\n",
       " '##се': 855,\n",
       " 'при': 856,\n",
       " '##же': 857,\n",
       " '##ча': 858,\n",
       " '##по': 859,\n",
       " '##ци': 860,\n",
       " '##ста': 861,\n",
       " '##сь': 862,\n",
       " '##ры': 863,\n",
       " '##си': 864,\n",
       " 'го': 865,\n",
       " '##ве': 866,\n",
       " '##сть': 867,\n",
       " '##ей': 868,\n",
       " '##за': 869,\n",
       " 'об': 870,\n",
       " 'ка': 871,\n",
       " '##ку': 872,\n",
       " '##ну': 873,\n",
       " '##ду': 874,\n",
       " '##сти': 875,\n",
       " 'но': 876,\n",
       " '##сто': 877,\n",
       " '##му': 878,\n",
       " 'как': 879,\n",
       " '##ши': 880,\n",
       " 'та': 881,\n",
       " '##льно': 882,\n",
       " 'из': 883,\n",
       " '##со': 884,\n",
       " '##ют': 885,\n",
       " 'да': 886,\n",
       " 'ни': 887,\n",
       " 'все': 888,\n",
       " '##хо': 889,\n",
       " '##па': 890,\n",
       " '##лу': 891,\n",
       " '##ше': 892,\n",
       " 'раз': 893,\n",
       " '##га': 894,\n",
       " '##ще': 895,\n",
       " 'бо': 896,\n",
       " '##ги': 897,\n",
       " '##ере': 898,\n",
       " '##жно': 899,\n",
       " 'ре': 900,\n",
       " '##ный': 901,\n",
       " '##ту': 902,\n",
       " '##вы': 903,\n",
       " 'те': 904,\n",
       " '##ме': 905,\n",
       " '##ные': 906,\n",
       " '##са': 907,\n",
       " 'де': 908,\n",
       " '##ня': 909,\n",
       " '##енно': 910,\n",
       " '##пи': 911,\n",
       " '##ень': 912,\n",
       " '##ты': 913,\n",
       " 'По': 914,\n",
       " '##кой': 915,\n",
       " 'хо': 916,\n",
       " '##ется': 917,\n",
       " 'под': 918,\n",
       " '##..': 919,\n",
       " '##жи': 920,\n",
       " '##ения': 921,\n",
       " '##че': 922,\n",
       " 'са': 923,\n",
       " 'ва': 924,\n",
       " 'ма': 925,\n",
       " '##вать': 926,\n",
       " 'так': 927,\n",
       " '##би': 928,\n",
       " '##чно': 929,\n",
       " 'кото': 930,\n",
       " '##лько': 931,\n",
       " 'пре': 932,\n",
       " '##гда': 933,\n",
       " '##щи': 934,\n",
       " 'бу': 935,\n",
       " '##ных': 936,\n",
       " '##сли': 937,\n",
       " '##ение': 938,\n",
       " '##жа': 939,\n",
       " 'же': 940,\n",
       " '##вер': 941,\n",
       " 'ли': 942,\n",
       " '##ря': 943,\n",
       " 'па': 944,\n",
       " '##ств': 945,\n",
       " '##дно': 946,\n",
       " '##ут': 947,\n",
       " '##бы': 948,\n",
       " 'для': 949,\n",
       " 'сво': 950,\n",
       " '##зо': 951,\n",
       " '##бе': 952,\n",
       " '##шь': 953,\n",
       " '##ски': 954,\n",
       " '##чес': 955,\n",
       " '##лю': 956,\n",
       " 'ста': 957,\n",
       " '##дет': 958,\n",
       " '##ско': 959,\n",
       " '##ная': 960,\n",
       " 'си': 961,\n",
       " 'ме': 962,\n",
       " 'ст': 963,\n",
       " '##зи': 964,\n",
       " 'ви': 965,\n",
       " 'ми': 966,\n",
       " 'лю': 967,\n",
       " '##мен': 968,\n",
       " 'сто': 969,\n",
       " '##мер': 970,\n",
       " '...': 971,\n",
       " '##вно': 972,\n",
       " 'зна': 973,\n",
       " '##пе': 974,\n",
       " '##ке': 975,\n",
       " 'се': 976,\n",
       " '##вет': 977,\n",
       " '##ша': 978,\n",
       " '##рем': 979,\n",
       " '##мы': 980,\n",
       " '##жет': 981,\n",
       " '##ды': 982,\n",
       " 'мен': 983,\n",
       " '##об': 984,\n",
       " '##ного': 985,\n",
       " '##тер': 986,\n",
       " '##про': 987,\n",
       " 'он': 988,\n",
       " '##ться': 989,\n",
       " '##ят': 990,\n",
       " '##ез': 991,\n",
       " 'На': 992,\n",
       " '##каза': 993,\n",
       " '##ство': 994,\n",
       " 'мы': 995,\n",
       " '##сле': 996,\n",
       " 'или': 997,\n",
       " '##ров': 998,\n",
       " 'есть': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] Пример текста для токенизации [SEP] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "example_text = tokenizer.decode(bert_input.input_ids[0])\n",
    "\n",
    "print(example_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Загрузка данных  <a id='section_1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Загрузим и просмотрим данные из тренировочного и валидационного датасетов**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@alisachachka не уезжаааааааай. :(❤ я тоже не ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @GalyginVadim: Ребята и девчата!\\nВсе в кин...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @ARTEM_KLYUSHIN: Кто ненавидит пробки ретви...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>RT @epupybobv: Хочется котлету по-киевски. Зап...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>@KarineKurganova @Yess__Boss босапопа есбоса н...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  class\n",
       "0   0  @alisachachka не уезжаааааааай. :(❤ я тоже не ...      0\n",
       "1   1  RT @GalyginVadim: Ребята и девчата!\\nВсе в кин...      1\n",
       "2   2  RT @ARTEM_KLYUSHIN: Кто ненавидит пробки ретви...      0\n",
       "3   3  RT @epupybobv: Хочется котлету по-киевски. Зап...      1\n",
       "4   4  @KarineKurganova @Yess__Boss босапопа есбоса н...      1"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"data/transforms/train.csv\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>181467</td>\n",
       "      <td>RT @TukvaSociopat: Максимальный репост! ))) #є...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>181468</td>\n",
       "      <td>чтоб у меня з.п. ежегодно индексировали на инд...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>181469</td>\n",
       "      <td>@chilyandlime нехуя мне не хорошо !!! :((((</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>181470</td>\n",
       "      <td>@inafish нее , когда ногами ахахах когда?ахаха...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>181471</td>\n",
       "      <td>Хочу сделать как лучше,  а получаю как всегда. :(</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                               text  class\n",
       "0  181467  RT @TukvaSociopat: Максимальный репост! ))) #є...      1\n",
       "1  181468  чтоб у меня з.п. ежегодно индексировали на инд...      0\n",
       "2  181469        @chilyandlime нехуя мне не хорошо !!! :((((      0\n",
       "3  181470  @inafish нее , когда ногами ахахах когда?ахаха...      0\n",
       "4  181471  Хочу сделать как лучше,  а получаю как всегда. :(      0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val = pd.read_csv(\"data/transforms/val.csv\")\n",
    "df_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@alisachachka не уезжаааааааай. :(❤ я тоже не хочу, чтобы ты уезжала.\n",
      "label is 0\n",
      "label by model is neutral with score 0.9937475919723511\n"
     ]
    }
   ],
   "source": [
    "sentiment = pipeline(\"text-classification\", model='SkolkovoInstitute/russian_toxicity_classifier')\n",
    "\n",
    "idx = 0\n",
    "print(df_train.iloc[idx]['text'])\n",
    "print('label is', df_train.iloc[idx]['class'])\n",
    "print('label by model is', sentiment(df_train.iloc[idx]['text'])[0]['label'], 'with score', sentiment(df_train.iloc[idx]['text'])[0]['score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Dataset и Dataloader <a id='section_2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Создадим датасет и далаоадер для загруженных данных**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwitterDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, txts, labels):\n",
    "        self._labels = labels\n",
    "        \n",
    "        self.tokenizer = BertTokenizer.from_pretrained('SkolkovoInstitute/russian_toxicity_classifier')\n",
    "        #для каждого text возвращает батч с полями:\n",
    "               #'inputs_ids' -- тензор размера (B,1,max_len) из id токенов\n",
    "               #'token_type_ids' -- тензор размера (B,1,max_len) из id типов токенов\n",
    "               #'attention_mask' -- тензор размера (B,1,max_len) из индексов, указывающих, на какие токеты модель должна обратить внима\n",
    "        self._txts = [self.tokenizer(text, padding='max_length', max_length=10,\n",
    "                                     truncation=True, return_tensors=\"pt\")\n",
    "                      for text in txts]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self._txts)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self._txts[index], self._labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train['class'].values\n",
    "y_val = df_val['class'].values\n",
    "\n",
    "train_dataset = TwitterDataset(df_train['text'], y_train)\n",
    "valid_dataset = TwitterDataset(df_val['text'], y_val)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                          batch_size=64,\n",
    "                          shuffle=True,\n",
    "                          num_workers=0)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset,\n",
    "                          batch_size=64,\n",
    "                          shuffle=False,\n",
    "                          num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n",
      "torch.Size([64, 1, 10])\n",
      "torch.Size([64, 1, 10])\n"
     ]
    }
   ],
   "source": [
    "for txt, lbl in train_loader:\n",
    "    print(txt.keys()) #словарь с ключами'input_ids', 'token_type_ids', 'attention_mask'\n",
    "    print(txt['input_ids'].shape) #тензор размера (B,1,max_len) из id токенов\n",
    "    print(txt['attention_mask'].shape) #тензор размера (B,1,max_len) из индексов, указывающих, на какие токеты модель должна обратить внимание\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Метрика модели 'SkolkovoInstitute/russian_toxicity_classifier' на валидационном датасете <a id='section_3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вычислим метрику f1_score модели SkolkovoInstitute/russian_toxicity_classifier на валидационном датасете**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val f1_score: 0.486\n"
     ]
    }
   ],
   "source": [
    "#метрика модели на валидационном датасете\n",
    "model_bert = BertForSequenceClassification.from_pretrained('SkolkovoInstitute/russian_toxicity_classifier')\n",
    "\n",
    "valid_f1 = torchmetrics.F1Score()\n",
    "\n",
    "for val_input, val_label in valid_loader:\n",
    "    val_label = val_label\n",
    "    mask = val_input['attention_mask'] \n",
    "    input_id = val_input['input_ids'].squeeze(1)\n",
    "    \n",
    "    output = model_bert(input_id, mask)[0]\n",
    "    \n",
    "    valid_f1(output, val_label)\n",
    "    \n",
    "print(f'Val f1_score: {valid_f1.compute().item():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Дообученная модель 'SkolkovoInstitute/russian_toxicity_classifier' и ее метрики <a id='section_4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Дообучим слой classifier модели SkolkovoInstitute/russian_toxicity_classifier и вычислим ее метрики на тренировочном и валидационном датасетах**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertForSequenceClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
      ")\n",
      "Parameters full train: 177854978\n",
      "Parameters transfer learning: 1538\n"
     ]
    }
   ],
   "source": [
    "#инициализация модели классификации сентимента текста\n",
    "model = BertForSequenceClassification.from_pretrained('SkolkovoInstitute/russian_toxicity_classifier')\n",
    "print(model)\n",
    "print(\"Parameters full train:\", sum([param.nelement() for param in model.parameters()]))\n",
    "print(\"Parameters transfer learning:\", sum([param.nelement() for param in model.classifier.parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#компиляция модели\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# обучаем последний слой классификации\n",
    "optimizer = Adam(model.classifier.parameters(), lr=0.001)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 2836/2836 [1:55:31<00:00,  2.44s/it]\n",
      "  0%|                                                                                         | 0/2836 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 | Train Loss:  0.011         | Train f1:  0.582         | Val Loss:  0.010         | Val f1:  0.615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 2836/2836 [1:49:40<00:00,  2.32s/it]\n",
      "  0%|                                                                                         | 0/2836 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 | Train Loss:  0.010         | Train f1:  0.594         | Val Loss:  0.011         | Val f1:  0.577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 2836/2836 [1:49:36<00:00,  2.32s/it]\n",
      "  0%|                                                                                         | 0/2836 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3 | Train Loss:  0.010         | Train f1:  0.595         | Val Loss:  0.010         | Val f1:  0.623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 2836/2836 [1:48:58<00:00,  2.31s/it]\n",
      "  0%|                                                                                         | 0/2836 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 4 | Train Loss:  0.010         | Train f1:  0.594         | Val Loss:  0.010         | Val f1:  0.615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 2836/2836 [1:50:28<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5 | Train Loss:  0.010         | Train f1:  0.596         | Val Loss:  0.010         | Val f1:  0.620\n",
      "Wall time: 9h 32min 40s\n"
     ]
    }
   ],
   "source": [
    "#дообучение модели и подсчет метрик на тренировочном и валидационном датасетах\n",
    "\n",
    "train_f1 = torchmetrics.F1Score()\n",
    "valid_f1 = torchmetrics.F1Score()\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss_train = 0.0\n",
    "    for train_input, train_label in tqdm(train_loader):\n",
    "        mask = train_input['attention_mask']\n",
    "        input_id = train_input['input_ids'].squeeze(1)\n",
    "        train_label = train_label\n",
    "\n",
    "        output = model(input_id, mask)[0]\n",
    "                \n",
    "        batch_loss = criterion(output, train_label)\n",
    "        total_loss_train += batch_loss.item()\n",
    "                \n",
    "        train_f1(output, train_label)\n",
    "        \n",
    "        model.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "    model.eval()\n",
    "    total_loss_val = 0.0\n",
    "    for val_input, val_label in valid_loader:\n",
    "        val_label = val_label\n",
    "        mask = val_input['attention_mask']\n",
    "        input_id = val_input['input_ids'].squeeze(1)\n",
    "\n",
    "        output = model(input_id, mask)[0]\n",
    "\n",
    "        batch_loss = criterion(output, val_label)\n",
    "        total_loss_val += batch_loss.item()\n",
    "                    \n",
    "        valid_f1(output, val_label)\n",
    "            \n",
    "    print(\n",
    "        f'Epochs: {epoch + 1} | Train Loss: {total_loss_train / len(train_dataset): .3f} \\\n",
    "        | Train f1: {train_f1.compute().item(): .3f} \\\n",
    "        | Val Loss: {total_loss_val / len(valid_dataset): .3f} \\\n",
    "        | Val f1: {valid_f1.compute().item(): .3f}')\n",
    "    train_f1.reset()\n",
    "    valid_f1.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val f1_score: 0.620\n"
     ]
    }
   ],
   "source": [
    "#метрика дообученной модели на валидационном датасете\n",
    "valid_f1 = torchmetrics.F1Score()\n",
    "model.eval()\n",
    "\n",
    "for val_input, val_label in valid_loader:\n",
    "    val_label = val_label\n",
    "    mask = val_input['attention_mask'] \n",
    "    input_id = val_input['input_ids'].squeeze(1)\n",
    "    \n",
    "    output = model(input_id, mask)[0]\n",
    "    \n",
    "    valid_f1(output, val_label)\n",
    "    \n",
    "print(f'Val f1_score: {valid_f1.compute().item():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Добавим к выходу модели SkolkovoInstitute/russian_toxicity_classifier сигмоиду, дообучим последний слой классификации и вычислим ее метрики на тренировочном и валидационном датасетах**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#класс модели BertClassifier\n",
    "class BertClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.bert = BertForSequenceClassification.from_pretrained('SkolkovoInstitute/russian_toxicity_classifier')\n",
    "        self.sigm = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        pooled_output = self.bert(input_ids=x, attention_mask=mask,return_dict=False)[0]  #(B, 2)\n",
    "        final_layer = self.sigm(pooled_output)\n",
    "        return final_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertClassifier(\n",
      "  (bert): BertForSequenceClassification(\n",
      "    (bert): BertModel(\n",
      "      (embeddings): BertEmbeddings(\n",
      "        (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
      "        (position_embeddings): Embedding(512, 768)\n",
      "        (token_type_embeddings): Embedding(2, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): BertEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (2): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (3): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (4): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (5): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (6): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (7): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (8): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (9): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (10): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (11): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): BertPooler(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "    )\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
      "  )\n",
      "  (sigm): Sigmoid()\n",
      ")\n",
      "Parameters full train: 177854978\n",
      "Parameters transfer learning: 1538\n"
     ]
    }
   ],
   "source": [
    "#инициализация модели\n",
    "model_sigm = BertClassifier()\n",
    "print(model_sigm)\n",
    "print(\"Parameters full train:\", sum([param.nelement() for param in model_sigm.parameters()]))\n",
    "print(\"Parameters transfer learning:\", sum([param.nelement() for param in model_sigm.bert.classifier.parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#компиляция модели\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#дообучаем последний слой классификации\n",
    "optimizer = Adam(model_sigm.bert.classifier.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 2836/2836 [1:48:53<00:00,  2.30s/it]\n",
      "  0%|                                                                                         | 0/2836 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 | Train Loss:  0.011         | Train f1:  0.586         | Val Loss:  0.010         | Val f1:  0.598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 2836/2836 [1:45:10<00:00,  2.23s/it]\n",
      "  0%|                                                                                         | 0/2836 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 | Train Loss:  0.010         | Train f1:  0.603         | Val Loss:  0.010         | Val f1:  0.606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 2836/2836 [1:45:17<00:00,  2.23s/it]\n",
      "  0%|                                                                                         | 0/2836 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3 | Train Loss:  0.010         | Train f1:  0.607         | Val Loss:  0.010         | Val f1:  0.607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 2836/2836 [1:50:04<00:00,  2.33s/it]\n",
      "  0%|                                                                                         | 0/2836 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 4 | Train Loss:  0.010         | Train f1:  0.608         | Val Loss:  0.010         | Val f1:  0.613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 2836/2836 [1:46:35<00:00,  2.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5 | Train Loss:  0.010         | Train f1:  0.609         | Val Loss:  0.010         | Val f1:  0.615\n"
     ]
    }
   ],
   "source": [
    "#дообучение модели и подсчет метрик на тренировочном и валидационном датасетах\n",
    "\n",
    "train_f1 = torchmetrics.F1Score()\n",
    "valid_f1 = torchmetrics.F1Score()\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model_sigm.train()\n",
    "    total_loss_train = 0.0\n",
    "    for train_input, train_label in tqdm(train_loader):\n",
    "        mask = train_input['attention_mask']\n",
    "        input_id = train_input['input_ids'].squeeze(1)\n",
    "        train_label = train_label\n",
    "\n",
    "        output = model_sigm(input_id, mask)\n",
    "                \n",
    "        batch_loss = criterion(output, train_label)\n",
    "        total_loss_train += batch_loss.item()\n",
    "                \n",
    "        train_f1(output, train_label)\n",
    "        \n",
    "        model_sigm.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "    model_sigm.eval()\n",
    "    total_loss_val = 0.0\n",
    "    for val_input, val_label in valid_loader:\n",
    "        val_label = val_label\n",
    "        mask = val_input['attention_mask']\n",
    "        input_id = val_input['input_ids'].squeeze(1)\n",
    "\n",
    "        output = model_sigm(input_id, mask)\n",
    "\n",
    "        batch_loss = criterion(output, val_label)\n",
    "        total_loss_val += batch_loss.item()\n",
    "                    \n",
    "        valid_f1(output, val_label)\n",
    "            \n",
    "    print(\n",
    "        f'Epochs: {epoch + 1} | Train Loss: {total_loss_train / len(train_dataset): .3f} \\\n",
    "        | Train f1: {train_f1.compute().item(): .3f} \\\n",
    "        | Val Loss: {total_loss_val / len(valid_dataset): .3f} \\\n",
    "        | Val f1: {valid_f1.compute().item(): .3f}')\n",
    "    train_f1.reset()\n",
    "    valid_f1.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val f1_score: 0.615\n"
     ]
    }
   ],
   "source": [
    "#метрика дообученной модели на валидационном датасете\n",
    "valid_f1 = torchmetrics.F1Score()\n",
    "model_sigm.eval()\n",
    "\n",
    "for val_input, val_label in valid_loader:\n",
    "    val_label = val_label\n",
    "    mask = val_input['attention_mask'] \n",
    "    input_id = val_input['input_ids'].squeeze(1)\n",
    "    \n",
    "    output = model_sigm(input_id, mask)\n",
    "    \n",
    "    valid_f1(output, val_label)\n",
    "    \n",
    "print(f'Val f1_score: {valid_f1.compute().item():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Выводы <a id='section_5'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В настоящей работе была рассмотрена модель классификации сантимента текста SkolkovoInstitute/russian_toxicity_classifier. \n",
    "\n",
    "Метрика f1_score модели на валидационном датасете:\n",
    "- до дообучения -- 0.486, \n",
    "- после дообучения -- 0.620,\n",
    "- после дообучения с применением сигмоиды -- 0.615.\n",
    "\n",
    "Таким образом, дообучение модели на тренировочном датасете способствует увеличению значения метрики, при этом использование логитов дает лучший результат по сравнению с применением функции активации сигмоиды на последнем слое классификации. \n",
    "\n",
    "P.S. Отметим также, что дообучение модели занимает большое количество времени (около 2 часов на эпоху), что объясняет выбор числа эпох равного 5 в настоящей работе."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
